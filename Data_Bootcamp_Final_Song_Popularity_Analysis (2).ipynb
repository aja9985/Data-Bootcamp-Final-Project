{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Data Bootcamp Final Project\n",
        "####Explaining Music Popularity Using Audio Features and Machine Learning\n",
        "\n",
        "Done by: Deema Hazim and Ameera Alrahmah"
      ],
      "metadata": {
        "id": "NoHWqQ0i-hLQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Which audio features matter most for popularity?"
      ],
      "metadata": {
        "id": "_QMsZC_kZyLy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "PQqEMFzgPicw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from datasets import load_dataset"
      ],
      "metadata": {
        "id": "ipFNtGVSaCuY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load spotify tracks dataset\n",
        "dataset = load_dataset(\"maharshipandya/spotify-tracks-dataset\")\n",
        "df = pd.DataFrame(dataset[\"train\"])"
      ],
      "metadata": {
        "id": "NtytwxHORr6L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "u-9oJxs3WE9y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "rkjR4bvCR1S-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Select the audio feature columns we want to analyze\n",
        "audio_features = [\n",
        "    'danceability',\n",
        "    'energy',\n",
        "    'loudness',\n",
        "    'speechiness',\n",
        "    'acousticness',\n",
        "    'instrumentalness',\n",
        "    'liveness',\n",
        "    'valence',\n",
        "    'tempo'\n",
        "]\n",
        "\n",
        "# Select features and target\n",
        "df_model = df[audio_features + ['popularity']]"
      ],
      "metadata": {
        "id": "nNerp2ZFaCsS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_model.head()"
      ],
      "metadata": {
        "id": "jgz9LTRDk51g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_model.describe()"
      ],
      "metadata": {
        "id": "T8vXPXE3k5tu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define features and target\n",
        "X = df_model[audio_features]\n",
        "y = df_model['popularity']"
      ],
      "metadata": {
        "id": "VYAb0vn9W1J6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Standardize features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "4cMRDbbiaCp8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train linear regression model\n",
        "lin_reg = LinearRegression()\n",
        "lin_reg.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "id": "7eI4ufwcaCnY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create data frame of feature coefficients (shows the correlation with popularity)\n",
        "coefficients = pd.DataFrame({\n",
        "    'Feature': audio_features,\n",
        "    'Coefficient': lin_reg.coef_\n",
        "}).sort_values(by='Coefficient', ascending=False)\n",
        "\n",
        "coefficients"
      ],
      "metadata": {
        "id": "GpaxJZhPaDT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error\n",
        "\n",
        "# Generate predictions for training and test sets\n",
        "y_pred_train = lin_reg.predict(X_train_scaled)\n",
        "y_pred_test = lin_reg.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model performance on train and test data\n",
        "# R-squared shows how well the model explains popularity\n",
        "# while RMSE and MAE indicate the average error in predicted popularity\n",
        "print(\"Model Performance:\")\n",
        "print(f\"Train R-squared: {r2_score(y_train, y_pred_train):.3f}\")\n",
        "print(f\"Test R-squared: {r2_score(y_test, y_pred_test):.3f}\")\n",
        "print(f\"Test RMSE: {np.sqrt(mean_squared_error(y_test, y_pred_test)):.2f}\")\n",
        "print(f\"Test MAE: {mean_absolute_error(y_test, y_pred_test):.2f}\")"
      ],
      "metadata": {
        "id": "44N94hbC3dh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Can we classify songs as “hit” vs “non-hit”?**"
      ],
      "metadata": {
        "id": "K-SPB3vTZyJs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ],
      "metadata": {
        "id": "GmLQ08D7aEKW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define what makes a song a \"hit\"\n",
        "df['is_hit'] = (df['popularity'] >= 50).astype(int)"
      ],
      "metadata": {
        "id": "JvzDKmt6aD_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Hit Distribution:\")\n",
        "print(df['is_hit'].value_counts())"
      ],
      "metadata": {
        "id": "pvIUP3ZlaD9B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Prepare the data (same features as before)\n",
        "X = df[audio_features]\n",
        "y = df['is_hit']"
      ],
      "metadata": {
        "id": "VD27DQQaaD6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "S4iId6DnaD4q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Scale the features\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "SlwJ33DYlpB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Logistic Regression\n",
        "log_reg = LogisticRegression(random_state=42)\n",
        "log_reg.fit(X_train_scaled, y_train)\n",
        "y_pred_lr = log_reg.predict(X_test_scaled)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_lr):.3f}\")\n",
        "print(classification_report(y_test, y_pred_lr))"
      ],
      "metadata": {
        "id": "Uq35N40jlq6N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Decision Tree\n",
        "tree = DecisionTreeClassifier(random_state=42, max_depth=5)\n",
        "tree.fit(X_train_scaled, y_train)\n",
        "y_pred_tree = tree.predict(X_test_scaled)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_tree):.3f}\")\n",
        "print(classification_report(y_test, y_pred_tree))"
      ],
      "metadata": {
        "id": "eYT7cHmIlwt0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Random Forest\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_scaled, y_train)\n",
        "y_pred_rf = rf.predict(X_test_scaled)\n",
        "\n",
        "print(f\"Accuracy: {accuracy_score(y_test, y_pred_rf):.3f}\")\n",
        "print(classification_report(y_test, y_pred_rf))"
      ],
      "metadata": {
        "id": "dT1_rsUjmEzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "models_comparison = pd.DataFrame({\n",
        "    'Model': ['Logistic Regression', 'Decision Tree', 'Random Forest'],\n",
        "    'Accuracy': [\n",
        "        accuracy_score(y_test, y_pred_lr),\n",
        "        accuracy_score(y_test, y_pred_tree),\n",
        "        accuracy_score(y_test, y_pred_rf)\n",
        "    ]\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.bar(models_comparison['Model'], models_comparison['Accuracy'], color=['blue', 'green', 'orange'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Model Performance Comparison')\n",
        "plt.ylim([0, 1])\n",
        "for i, v in enumerate(models_comparison['Accuracy']):\n",
        "    plt.text(i, v + 0.02, f'{v:.3f}', ha='center', fontweight='bold')\n",
        "plt.xticks(rotation=15, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "-KHCoCGlHwKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Confusion Matrix for each model\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "#Logistic Regression\n",
        "cm_lr = confusion_matrix(y_test, y_pred_lr)\n",
        "sns.heatmap(cm_lr, annot=True, fmt='d', cmap='Blues', ax=axes[0])\n",
        "axes[0].set_title('Logistic Regression')\n",
        "axes[0].set_ylabel('Actual')\n",
        "axes[0].set_xlabel('Predicted')\n",
        "\n",
        "#Decision Tree\n",
        "cm_tree = confusion_matrix(y_test, y_pred_tree)\n",
        "sns.heatmap(cm_tree, annot=True, fmt='d', cmap='Greens', ax=axes[1])\n",
        "axes[1].set_title('Decision Tree')\n",
        "axes[1].set_ylabel('Actual')\n",
        "axes[1].set_xlabel('Predicted')\n",
        "\n",
        "#Random Forest\n",
        "cm_rf = confusion_matrix(y_test, y_pred_rf)\n",
        "sns.heatmap(cm_rf, annot=True, fmt='d', cmap='Oranges', ax=axes[2])\n",
        "axes[2].set_title('Random Forest')\n",
        "axes[2].set_ylabel('Actual')\n",
        "axes[2].set_xlabel('Predicted')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ESL7akT5mK2O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Let us see if different hit thresholds matter"
      ],
      "metadata": {
        "id": "6balnzJOJRbA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "thresholds = [40, 50, 60, 70]\n",
        "\n",
        "for threshold in thresholds:\n",
        "    df['is_hit'] = (df['popularity'] >= threshold).astype(int)\n",
        "\n",
        "    # How many hits?\n",
        "    hit_pct = df['is_hit'].mean() * 100\n",
        "    print(f\"Threshold {threshold}: {hit_pct:.1f}% of songs are hits\")\n",
        "\n",
        "    # Train model\n",
        "    y = df['is_hit']\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    scaler = StandardScaler()\n",
        "    X_train_scaled = scaler.fit_transform(X_train)\n",
        "    X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    rf.fit(X_train_scaled, y_train)\n",
        "    y_pred = rf.predict(X_test_scaled)\n",
        "\n",
        "    print(f\"  Accuracy: {accuracy_score(y_test, y_pred):.3f}\\n\")\n"
      ],
      "metadata": {
        "id": "ZxDV2PRLJYXb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Let us explore what makes hits different from non-hits"
      ],
      "metadata": {
        "id": "9Jeh-vogL-rj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df['is_hit'] = (df['popularity'] >= 50).astype(int)\n",
        "hits = df[df['is_hit'] == 1]\n",
        "non_hits = df[df['is_hit'] == 0]\n",
        "\n",
        "#Compare average features\n",
        "comparison = pd.DataFrame({\n",
        "    'Feature': audio_features,\n",
        "    'Hits': [hits[f].mean() for f in audio_features],\n",
        "    'Non-Hits': [non_hits[f].mean() for f in audio_features]\n",
        "})\n",
        "comparison['Difference'] = comparison['Hits'] - comparison['Non-Hits']\n",
        "comparison = comparison.sort_values('Difference', ascending=False)\n",
        "\n",
        "print(comparison.round(3))"
      ],
      "metadata": {
        "id": "Y28BSZU-KncL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(10, 6))\n",
        "colors = ['green' if x > 0 else 'red' for x in comparison['Difference']]\n",
        "plt.barh(comparison['Feature'], comparison['Difference'], color=colors)\n",
        "plt.xlabel('Difference (Hits - Non-Hits)')\n",
        "plt.title('Hits Have More Green and Less Red')\n",
        "plt.axvline(x=0, color='black', linestyle='--')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "4oV-Ee27Kq12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Do genre or artist popularity improve prediction accuracy?**"
      ],
      "metadata": {
        "id": "bYMYD2DZZyHY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Baseline: Audio Features Only (what we already have)\n",
        "print(\"BASELINE: Audio Features Only\")\n",
        "\n",
        "df['is_hit'] = (df['popularity'] >= 50).astype(int)\n",
        "\n",
        "X_audio = df[audio_features]\n",
        "y = df['is_hit']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_audio, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "rf_baseline = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_baseline.fit(X_train_scaled, y_train)\n",
        "y_pred_baseline = rf_baseline.predict(X_test_scaled)\n",
        "\n",
        "baseline_accuracy = accuracy_score(y_test, y_pred_baseline)\n",
        "print(f\"Accuracy with only audio features: {baseline_accuracy:.3f}\")"
      ],
      "metadata": {
        "id": "oBeCEvl4aE_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Audio Features + Genre\n",
        "\n",
        "#Create genre dummies (one-hot encoding)\n",
        "genre_dummies = pd.get_dummies(df['track_genre'], prefix='genre')\n",
        "\n",
        "#Combine audio features with genre\n",
        "X_with_genre = pd.concat([df[audio_features], genre_dummies], axis=1)\n",
        "\n",
        "X_train_g, X_test_g, y_train_g, y_test_g = train_test_split(\n",
        "    X_with_genre, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler_g = StandardScaler()\n",
        "X_train_g_scaled = scaler_g.fit_transform(X_train_g)\n",
        "X_test_g_scaled = scaler_g.transform(X_test_g)\n",
        "\n",
        "rf_genre = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_genre.fit(X_train_g_scaled, y_train_g)\n",
        "y_pred_genre = rf_genre.predict(X_test_g_scaled)\n",
        "\n",
        "genre_accuracy = accuracy_score(y_test_g, y_pred_genre)\n",
        "print(f\"Accuracy with audio + genre: {genre_accuracy:.3f}\")\n",
        "print(f\"Improvement: {(genre_accuracy - baseline_accuracy):.3f} ({((genre_accuracy - baseline_accuracy)/baseline_accuracy)*100:.1f}%)\")"
      ],
      "metadata": {
        "id": "uXUBDfrcaE9F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Audio features + artist popularity\n",
        "\n",
        "# Calculate artist average popularity\n",
        "artist_pop = df.groupby('artists')['popularity'].mean().to_dict()\n",
        "df['artist_avg_popularity'] = df['artists'].map(artist_pop)\n",
        "\n",
        "# Combine audio features with artist popularity\n",
        "X_with_artist = df[audio_features + ['artist_avg_popularity']]\n",
        "\n",
        "X_train_a, X_test_a, y_train_a, y_test_a = train_test_split(\n",
        "    X_with_artist, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler_a = StandardScaler()\n",
        "X_train_a_scaled = scaler_a.fit_transform(X_train_a)\n",
        "X_test_a_scaled = scaler_a.transform(X_test_a)\n",
        "\n",
        "rf_artist = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_artist.fit(X_train_a_scaled, y_train_a)\n",
        "y_pred_artist = rf_artist.predict(X_test_a_scaled)\n",
        "\n",
        "artist_accuracy = accuracy_score(y_test_a, y_pred_artist)\n",
        "print(f\"Accuracy with audio + artist: {artist_accuracy:.3f}\")\n",
        "print(f\"Improvement: {(artist_accuracy - baseline_accuracy):.3f} ({((artist_accuracy - baseline_accuracy)/baseline_accuracy)*100:.1f}%)\")"
      ],
      "metadata": {
        "id": "1BF4THrEaE6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Audio + Genre + Artist\n",
        "\n",
        "X_full = pd.concat([df[audio_features], genre_dummies, df[['artist_avg_popularity']]], axis=1)\n",
        "\n",
        "X_train_f, X_test_f, y_train_f, y_test_f = train_test_split(\n",
        "    X_full, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "scaler_f = StandardScaler()\n",
        "X_train_f_scaled = scaler_f.fit_transform(X_train_f)\n",
        "X_test_f_scaled = scaler_f.transform(X_test_f)\n",
        "\n",
        "rf_full = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_full.fit(X_train_f_scaled, y_train_f)\n",
        "y_pred_full = rf_full.predict(X_test_f_scaled)\n",
        "\n",
        "full_accuracy = accuracy_score(y_test_f, y_pred_full)\n",
        "print(f\"Accuracy with all features: {full_accuracy:.3f}\")\n",
        "print(f\"Improvement: {(full_accuracy - baseline_accuracy):.3f} ({((full_accuracy - baseline_accuracy)/baseline_accuracy)*100:.1f}%)\")"
      ],
      "metadata": {
        "id": "Cnop-YYZaE4Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results_df = pd.DataFrame({\n",
        "    'Model': ['Audio Only', 'Audio + Genre', 'Audio + Artist', 'All Combined'],\n",
        "    'Accuracy': [baseline_accuracy, genre_accuracy, artist_accuracy, full_accuracy]\n",
        "})\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "bars = plt.bar(results_df['Model'], results_df['Accuracy'], color=['blue', 'green', 'orange', 'red'])\n",
        "plt.ylabel('Accuracy')\n",
        "plt.title('Does Genre or Artist Information Improve Predictions?')\n",
        "plt.ylim([0.7, max(results_df['Accuracy']) + 0.05])\n",
        "\n",
        "# Add values on bars\n",
        "for i, bar in enumerate(bars):\n",
        "    height = bar.get_height()\n",
        "    plt.text(bar.get_x() + bar.get_width()/2., height,\n",
        "             f'{height:.3f}',\n",
        "             ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.xticks(rotation=15, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "gjOKkDeHeaYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Which Genres Have the Most Hits?\n",
        "\n",
        "genre_hit_rate = df.groupby('track_genre').agg({\n",
        "    'is_hit': ['mean', 'count']\n",
        "}).round(3)\n",
        "genre_hit_rate.columns = ['Hit_Rate', 'Total_Songs']\n",
        "genre_hit_rate = genre_hit_rate[genre_hit_rate['Total_Songs'] >= 100]  #cOnly genres with 100+ songs\n",
        "genre_hit_rate = genre_hit_rate.sort_values('Hit_Rate', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Genres by Hit Rate:\")\n",
        "print(genre_hit_rate.head(10))"
      ],
      "metadata": {
        "id": "vTlTTpAyed5Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Visualize top genres\n",
        "plt.figure(figsize=(12, 6))\n",
        "top_genres = genre_hit_rate.head(10)\n",
        "plt.barh(top_genres.index, top_genres['Hit_Rate'], color='purple')\n",
        "plt.xlabel('Hit Rate')\n",
        "plt.title('Top 10 Genres Most Likely to Produce Hits')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "te9DKKFLel9k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##**Do audio features cluster into underlying dimensions that explain why certain features matter for hit prediction?**"
      ],
      "metadata": {
        "id": "TBc7Ws7M-aPb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA"
      ],
      "metadata": {
        "id": "NufXri1XJ1IC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Using PCA analysis\n",
        "\n",
        "# Select the audio features and drop missing values\n",
        "X = df[audio_features].dropna()\n",
        "\n",
        "# Standardize features for PCA\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Run PCA\n",
        "pca = PCA()\n",
        "pca.fit(X_scaled)\n",
        "\n",
        "# Display the variance explained by each principal component\n",
        "variance = pca.explained_variance_ratio_ * 100\n",
        "cumulative = np.cumsum(variance)\n",
        "\n",
        "print(\"Variance explained by each component:\")\n",
        "for i in range(len(variance)):\n",
        "    print(f\"Component {i+1}: {variance[i]:.1f}% (Total: {cumulative[i]:.1f}%)\")"
      ],
      "metadata": {
        "id": "sDR6Qp30Jp_d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot the variance explained by each principal component\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.bar(range(1, 10), variance, color='skyblue')\n",
        "plt.xlabel('Component')\n",
        "plt.ylabel('% Variance Explained')\n",
        "plt.title('How Much Does Each Component Explain?')\n",
        "plt.axhline(y=10, color='red', linestyle='--', alpha=0.5)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wbIWpqjVJp9I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create table and heatmap of feature loadings for the first three components\n",
        "# (Only these 3 components are used because they each explain >10% of the variance)\n",
        "loadings = pd.DataFrame(\n",
        "    pca.components_[:3].T,\n",
        "    columns=['Comp 1', 'Comp 2', 'Comp 3'],\n",
        "    index=audio_features\n",
        ")\n",
        "\n",
        "print(\"\\nFeature Loadings:\")\n",
        "print(loadings.round(2))\n",
        "\n",
        "# Heatmap\n",
        "plt.figure(figsize=(8, 5))\n",
        "sns.heatmap(loadings.T, annot=True, cmap='coolwarm', center=0, fmt='.2f')\n",
        "plt.title('Which Features Load on Each Component?')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "T3wD92ApJp7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Show top 3 features contributing to each of the first three components\n",
        "print(\"\\nInterpretation:\")\n",
        "print(\"\\nComponent 1 - Top features:\")\n",
        "print(loadings['Comp 1'].abs().sort_values(ascending=False).head(3))\n",
        "\n",
        "print(\"\\nComponent 2 - Top features:\")\n",
        "print(loadings['Comp 2'].abs().sort_values(ascending=False).head(3))\n",
        "\n",
        "print(\"\\nComponent 3 - Top features:\")\n",
        "print(loadings['Comp 3'].abs().sort_values(ascending=False).head(3))"
      ],
      "metadata": {
        "id": "l39zd4XpJp48"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Reduce to first 3 components\n",
        "pca_3 = PCA(n_components=3)\n",
        "components = pca_3.fit_transform(X_scaled)\n",
        "\n",
        "# Add popularity\n",
        "df_simple = pd.DataFrame({\n",
        "    'Comp 1': components[:, 0],\n",
        "    'Comp 2': components[:, 1],\n",
        "    'Comp 3': components[:, 2],\n",
        "    'popularity': df.loc[X.index, 'popularity'].values\n",
        "})\n",
        "\n",
        "# Compute correlation of each component with popularity\n",
        "print(\"\\nCorrelation with Popularity:\")\n",
        "for col in ['Comp 1', 'Comp 2', 'Comp 3']:\n",
        "    corr = df_simple[col].corr(df_simple['popularity'])\n",
        "    print(f\"{col}: {corr:.3f}\")"
      ],
      "metadata": {
        "id": "yEbRBD4ZJp2q"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}